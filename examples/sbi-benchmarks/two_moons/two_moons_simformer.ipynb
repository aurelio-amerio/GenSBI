{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['JAX_PLATFORMS']=\"cpu\"\n",
    "os.environ['JAX_PLATFORMS']=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_model=False\n",
    "train_model=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "root = \"/lhome/ific/a/aamerio/github/cfm-jax\"\n",
    "sys.path.append(f\"{root}/examples/sbi-benchmarks\")\n",
    "sys.path.append(f\"{root}/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax.checkpoint as ocp\n",
    "# get the current notebook path\n",
    "notebook_path = f\"{root}/examples/sbi-benchmarks/two_moons\"\n",
    "checkpoint_dir = f\"{notebook_path}/checkpoints/two_moons_simformer\"\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/ific/a/aamerio/miniforge3/envs/cfm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax\n",
    "from optax.contrib import reduce_on_plateau\n",
    "\n",
    "from numpyro import distributions as dist\n",
    "\n",
    "from corner import corner\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 10  # @param{type:\"integer\"}\n",
    "# @markdown Number of epochs to wait before resuming normal operation after the learning rate reduction:\n",
    "COOLDOWN = 5  # @param{type:\"integer\"}\n",
    "# @markdown Factor by which to reduce the learning rate:\n",
    "FACTOR = 0.5  # @param{type:\"number\"}\n",
    "# @markdown Relative tolerance for measuring the new optimum:\n",
    "RTOL = 1e-4  # @param{type:\"number\"}\n",
    "# @markdown Number of iterations to accumulate an average value:\n",
    "ACCUMULATION_SIZE = 100\n",
    "# max LR\n",
    "MAX_LR = 1e-3  # @param{type:\"number\"}\n",
    "# Min scale for the learning rate:\n",
    "MIN_LR = 5e-5  # @param{type:\"number\"}\n",
    "MIN_SCALE = MIN_LR / MAX_LR  # @param{type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sbi_tasks import TwoMoons\n",
    "from utils.dataloader import InfiniteDataLoader\n",
    "\n",
    "from flow_matching.path.scheduler import CondOTScheduler\n",
    "from flow_matching.path import AffineProbPath\n",
    "from flow_matching.solver import ODESolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twomoons = TwoMoons()\n",
    "task = twomoons.task\n",
    "prior = twomoons.get_prior()\n",
    "simulator = twomoons.get_simulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=[\"size\"])\n",
    "def sample_prior(size):\n",
    "    return jnp.array(prior.sample((size,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_samples = task.get_reference_posterior_samples(num_observation=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(reference_samples[:, 0], reference_samples[:, 1], bins=(200,200), range=[(-1, 1), (-1, 1)], density=True)\n",
    "plt.xlim((-1,1))\n",
    "plt.ylim((-1,1))\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataset\n",
    "nsamples = int(1e5)\n",
    "val_size = 512\n",
    "theta = prior.sample((nsamples+val_size,))\n",
    "xs = jnp.array(simulator(theta))\n",
    "node_ids = jnp.array(twomoons.get_node_id())\n",
    "dim_theta = twomoons.get_theta_dim()\n",
    "dim_x = twomoons.get_x_dim()\n",
    "\n",
    "# turn them into jax arrays\n",
    "theta = jnp.array(theta)\n",
    "xs = jnp.array(xs)\n",
    "\n",
    "# concatenate the data, theta and xs\n",
    "data = jnp.concatenate((theta, xs), axis=-1)\n",
    "\n",
    "\n",
    "train_data = data[:nsamples]\n",
    "val_data = data[nsamples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4*1024 # the model greatly benefits from larger batch sizes to avoid overfitting, but this is limited by the GPU memory\n",
    "dataset = InfiniteDataLoader(train_data, batch_size, rng=nnx.Rngs(0).dataset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the CFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Simformer, SimformerParams, SimformerCFMLoss, SimformerConditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = AffineProbPath(scheduler=CondOTScheduler()) # define the probability path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_joint = len(twomoons.get_node_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = SimformerParams(\n",
    "    rngs = nnx.Rngs(0),\n",
    "    dim_value = 40,\n",
    "    dim_id = 40, \n",
    "    dim_condition = 10, \n",
    "    dim_joint= dim_joint,\n",
    "    fourier_features = 128,\n",
    "    num_heads = 4,\n",
    "    num_layers = 6,\n",
    "    widening_factor = 3,\n",
    "    qkv_features = 40, # this bottlenecks the transformer features to 40, instead of the token dimension\n",
    "    num_hidden_layers = 1,\n",
    "    dropout_rate = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_cfm = SimformerCFMLoss(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalize(rng: jax.random.PRNGKey, edge_mask: jax.Array):\n",
    "    # Simple function that marginializes out a single node from a adjacency matrix of a graph.\n",
    "    idx = jax.random.choice(rng, jnp.arange(edge_mask.shape[0]), shape=(1,), replace=False)\n",
    "    edge_mask = edge_mask.at[idx, :].set(False)\n",
    "    edge_mask = edge_mask.at[:, idx].set(False)\n",
    "    edge_mask = edge_mask.at[idx, idx].set(True)\n",
    "    return edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected_edge_mask = twomoons.get_edge_mask_fn(\"undirected\")(node_ids, None)\n",
    "posterior_faithfull = twomoons.get_edge_mask_fn(\"faithfull\")(node_ids, condition_mask=jnp.array([0,0,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=[\"nsamples\"])\n",
    "def get_random_condition_mask(rng: jax.random.PRNGKey, nsamples):\n",
    "    mask_joint = jnp.zeros((5*nsamples, dim_joint ), dtype=jnp.bool_)\n",
    "    mask_posterior = jnp.concatenate([jnp.zeros((nsamples, dim_theta), dtype=jnp.bool_), jnp.ones((nsamples, dim_x), dtype=jnp.bool_)], axis=-1)\n",
    "    # mask_likelihood = jnp.concatenate([jnp.ones((nsamples, dim_theta), dtype=jnp.bool_), jnp.zeros((nsamples, dim_x), dtype=jnp.bool_)], axis=-1)\n",
    "    \n",
    "    mask1 = jax.random.bernoulli(rng, p=0.3, shape=(nsamples, dim_joint))\n",
    "    filter = ~jnp.all(mask1, axis=-1)\n",
    "    mask1 = jnp.logical_and(mask1, filter.reshape(-1,1))\n",
    "\n",
    "    # masks = jnp.concatenate([mask_joint, mask1, mask_posterior, mask_likelihood], axis=0)\n",
    "    masks = jnp.concatenate([mask_joint, mask1, mask_posterior], axis=0)\n",
    "    return  jax.random.choice(rng, masks, shape=(nsamples,), replace=False, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_dist_model = dist.Independent(\n",
    "    dist.Normal(loc=jnp.zeros((4,)), scale=jnp.ones((4,))),\n",
    "    reinterpreted_batch_ndims=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_(vf_model, x_1, key: jax.random.PRNGKey):\n",
    "\n",
    "    batch_size = x_1.shape[0]\n",
    "\n",
    "    rng_x0, rng_t, rng_condition, rng_edge_mask1, rng_edge_mask2 = jax.random.split(key, 5)\n",
    "    \n",
    "    # Generate data and random times\n",
    "    x_0 = p0_dist_model.sample(rng_x0, (batch_size,)) # n, T_max, 1\n",
    "    \n",
    "    t = jax.random.uniform(rng_t, x_1.shape[0])\n",
    "\n",
    "    batch = (x_0, x_1, t)\n",
    "    \n",
    "    # Condition mask -> randomly condition on some data. Here you can choose between the different condition masks, and you should specify the conditionals you may want to compute afterwards.\n",
    "    condition_mask = get_random_condition_mask(rng_condition, batch_size)\n",
    "\n",
    "    # undirected_edge_mask \n",
    "    undirected_edge_mask_ = jnp.repeat(undirected_edge_mask[None,...], 3*batch_size, axis=0) # Dense default mask\n",
    "    \n",
    "    # faithfull posterior mask\n",
    "    faithfull_edge_mask_ = jnp.repeat(posterior_faithfull[None,...], 3*batch_size, axis=0) # Dense default mask\n",
    "    \n",
    "    # Include marginal consistency\n",
    "    marginal_mask = jax.vmap(marginalize, in_axes=(0,None))(jax.random.split(rng_edge_mask1, (batch_size,)), undirected_edge_mask)\n",
    "    edge_masks = jnp.concatenate([undirected_edge_mask_, faithfull_edge_mask_, marginal_mask], axis=0)\n",
    "    edge_masks = jax.random.choice(rng_edge_mask2, edge_masks, shape=(batch_size,), axis=0) # Randomly choose between dense and marginal mask\n",
    "\n",
    "\n",
    "    # Forward diffusion, do not perturb conditioned data\n",
    "    # Will use the condition mask to mask to prevent adding noise for nodes that are conditioned.\n",
    "    loss = loss_fn_cfm(vf_model, batch, node_ids=node_ids, edge_mask=edge_masks,condition_mask=condition_mask, )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_loss(vf_model, key: jax.random.PRNGKey):\n",
    "    x_1 = next(dataset) # n, T_max, 1\n",
    "    return loss_fn_(vf_model, x_1, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def val_loss(vf_model, key):\n",
    "    x_1 = val_data\n",
    "    return loss_fn_(vf_model, x_1, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(model, optimizer, rng):\n",
    "    loss_fn = lambda model: train_loss(model, rng)\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(grads, value=loss)  # In place updates.\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_model = Simformer(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model\n",
    "if restore_model:\n",
    "    model_state = nnx.state(vf_model)\n",
    "    graphdef, abstract_state = nnx.split(vf_model)\n",
    "\n",
    "    with ocp.CheckpointManager(\n",
    "        checkpoint_dir, options=ocp.CheckpointManagerOptions(read_only=True)\n",
    "    ) as read_mgr:\n",
    "        restored = read_mgr.restore(\n",
    "            1,\n",
    "            # pass in the model_state to restore the exact same State type\n",
    "            args=ocp.args.Composite(state=ocp.args.PyTreeRestore(item=model_state))\n",
    "        )\n",
    "\n",
    "    vf_model= nnx.merge(graphdef, restored[\"state\"])\n",
    "    print(\"Restored model from checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # linear learning rate schedule\n",
    "# nsteps = 10_000 \n",
    "# nepochs = 5\n",
    "\n",
    "\n",
    "# schedule = optax.schedules.linear_schedule(1e-3, 1e-6, 40000, 10000)\n",
    "\n",
    "# opt = optax.chain(optax.adaptive_grad_clip(10.0), optax.adamw(schedule))\n",
    "\n",
    "# # opt = optax.MultiSteps(opt, 2)\n",
    "\n",
    "# optimizer = nnx.Optimizer(vf_model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce on plateau schedule\n",
    "nsteps = 10_000\n",
    "nepochs = 10\n",
    "\n",
    "multistep = 1 # if the GPU cannot support batch sizes of at least 4k, adjust this value accordingly to get the desired effective batch size\n",
    "\n",
    "opt = optax.chain(\n",
    "    optax.adaptive_grad_clip(10.0),\n",
    "    optax.adamw(MAX_LR),\n",
    "    reduce_on_plateau(\n",
    "        patience=PATIENCE,\n",
    "        cooldown=COOLDOWN,\n",
    "        factor=FACTOR,\n",
    "        rtol=RTOL,\n",
    "        accumulation_size=ACCUMULATION_SIZE,\n",
    "        min_scale=MIN_SCALE,\n",
    "    ),\n",
    ")\n",
    "if multistep > 1:\n",
    "    opt = optax.MultiSteps(opt, multistep)\n",
    "optimizer = nnx.Optimizer(vf_model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rngs = nnx.Rngs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state = nnx.state(vf_model)\n",
    "best_val_loss_value = val_loss(vf_model, jax.random.PRNGKey(0))\n",
    "val_error_ratio = 1.1\n",
    "counter = 0\n",
    "cmax = 10\n",
    "print_every = 100\n",
    "\n",
    "loss_array = []\n",
    "val_loss_array = []\n",
    "\n",
    "early_stopping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:20<56:52:45, 20.48s/it]"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    vf_model.train()\n",
    "\n",
    "    for ep in range(nepochs):\n",
    "        pbar = tqdm(range(nsteps))\n",
    "        l = 0\n",
    "        v_l = 0\n",
    "        for j in pbar:\n",
    "            if counter > cmax and early_stopping:\n",
    "                print(\"Early stopping\")\n",
    "                # restore the model state\n",
    "                graphdef, abstract_state = nnx.split(vf_model)\n",
    "\n",
    "                vf_model = nnx.merge(graphdef, best_state)\n",
    "                break\n",
    "\n",
    "            loss = train_step(vf_model, optimizer, rngs.train_step())\n",
    "            l += loss.item()\n",
    "            \n",
    "            v_loss = val_loss(vf_model, rngs.val_step())\n",
    "            v_l += v_loss.item()\n",
    "\n",
    "            if j > 0 and j % 100 == 0:\n",
    "                loss_ = l / 100\n",
    "                val_ = v_l / 100\n",
    "\n",
    "                ratio1 = val_ / loss_\n",
    "                ratio2 = val_ / best_val_loss_value\n",
    "\n",
    "                # if ratio1 < val_error_ratio and ratio2 < 1.05:\n",
    "                if ratio1 < val_error_ratio:\n",
    "                    if val_ < best_val_loss_value:\n",
    "                        best_val_loss_value = val_\n",
    "                        best_state = nnx.state(vf_model)\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "\n",
    "                # scale = tree_get(optimizer.opt_state, \"ReduceLROnPlateauState\").scale.value\n",
    "                # pbar.set_postfix(loss=f\"{l/(100):.4f}\", ratio=f\"{ratio:.4f}\", counter=counter, lr_scale=scale, val_loss = f\"{val_:.4f}\" )\n",
    "                pbar.set_postfix(\n",
    "                    loss=f\"{loss_:.4f}\",\n",
    "                    ratio=f\"{ratio1:.4f}\",\n",
    "                    counter=counter,\n",
    "                    val_loss=f\"{val_:.4f}\",\n",
    "                )\n",
    "                loss_array.append(loss_)\n",
    "                val_loss_array.append(val_)\n",
    "                l = 0\n",
    "                v_l = 0\n",
    "\n",
    "            # if j>0 and j%3000 == 0:\n",
    "            #     idx = 8\n",
    "            #     vf_wrapped = FluxWrapper(vf_model)\n",
    "            #     samples, true_param, reference_samples = get_samples(vf_wrapped, idx)\n",
    "            #     plot_samples(samples, true_param)\n",
    "        # print(l)\n",
    "\n",
    "    vf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "if train_model:\n",
    "    checkpoint_manager = ocp.CheckpointManager(checkpoint_dir,\n",
    "        options=ocp.CheckpointManagerOptions(\n",
    "            max_to_keep=2,\n",
    "            keep_checkpoints_without_metrics=True,\n",
    "            create=True,\n",
    "        ),\n",
    "    )\n",
    "    model_state = nnx.state(vf_model)\n",
    "    checkpoint_manager.save(\n",
    "        1, args=ocp.args.Composite(state=ocp.args.PyTreeSave(model_state))\n",
    "    )\n",
    "\n",
    "    checkpoint_manager.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_array, label=\"train loss\")\n",
    "plt.plot(val_loss_array, label=\"val loss\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_matching.utils import ModelWrapper, GuidedModelWrapper\n",
    "class SimWrapper(ModelWrapper):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(model)\n",
    "\n",
    "    def __call__(self, x, t, args, **kwargs):\n",
    "        return self.model(obs=x, timesteps=t, **kwargs)\n",
    "\n",
    "class GuidedSimWrapper(GuidedModelWrapper):\n",
    "    def __init__(self, model, cfg_scale):\n",
    "        super().__init__(model, cfg_scale)\n",
    "\n",
    "    def __call__(self, x, t, args, **kwargs):\n",
    "        return self.model(obs=x, timesteps=t, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ids = jnp.array([0, 1])\n",
    "cond_ids = jnp.array([2, 3])\n",
    "step_size = 0.01\n",
    "\n",
    "# conditional sampling\n",
    "def get_samples(vf_wrapped, idx, nsamples=10_000, edge_mask=posterior_faithfull):\n",
    "    observation =  jnp.array(twomoons.get_observation(idx))\n",
    "    true_param = jnp.array(task.get_true_parameters(idx))\n",
    "    reference_samples = task.get_reference_posterior_samples(num_observation=idx)\n",
    "\n",
    "    rng = jax.random.PRNGKey(45)\n",
    "\n",
    "    key1,key2 = jax.random.split(rng, 2)\n",
    "\n",
    "    x_init = jax.random.normal(key1,(nsamples, dim_theta)) # n, T_max, 1\n",
    "    cond = jnp.broadcast_to(observation[...,None], (1, dim_x, 1)) # n, dim_theta, 1\n",
    "\n",
    "    solver = ODESolver(velocity_model=vf_wrapped)  # create an ODESolver class\n",
    "    model_extras = {\"cond\": cond, \"obs_ids\": obs_ids, \"cond_ids\": cond_ids, \"edge_mask\": edge_mask}\n",
    "\n",
    "    sampler_ = solver.get_sampler(method='Dopri5', step_size=step_size, return_intermediates=False, model_extras=model_extras)\n",
    "    samples = sampler_(x_init)  # sample from the model\n",
    "\n",
    "    return samples, true_param, reference_samples\n",
    "\n",
    "def plot_samples(samples, true_param):\n",
    "    plt.hist2d(samples[:,0], samples[:,1], bins=(200,200), range=[(-1, 1), (-1, 1)], density=True)\n",
    "    # same ratio on axis \n",
    "    plt.scatter(true_param[0,0], true_param[0,1], s=100, color='red', alpha=0.5, marker='x')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.xlim((-1,1))\n",
    "    plt.ylim((-1,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_cond = SimformerConditioner(vf_model)\n",
    "vf_wrapped = SimWrapper(vf_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to do conditional inference. We need an observation for which we want to ocmpute the posterior\n",
    "idx=8\n",
    "observation = jnp.array(twomoons.get_observation(idx))\n",
    "reference_samples = task.get_reference_posterior_samples(num_observation=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples(vf_wrapped, idx, nsamples=100_000)[0]\n",
    "# samples, true_param, reference_samples = get_samples(vf_wrapped, idx, nsamples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = samples\n",
    "\n",
    "plt.hist2d(posterior_samples[:,0], posterior_samples[:,1], bins=100, range=[(-1, 1), (-1, 1)], density=True)\n",
    "# same ratio on axis \n",
    "# plt.scatter(reference_samples[:,0], reference_samples[:,1], s=0.1, color='red', alpha=0.1, marker='x')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plt.xlim((-1,1))\n",
    "# plt.ylim((-1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(np.array(posterior_samples), bins=100, smooth=True, range=[(-1, 1), (-1, 1)], labels=['$\\\\theta_1$', '$\\\\theta_2$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(np.array(reference_samples), bins=100, smooth=True, range=[(-1, 1), (-1, 1)], labels=['$\\\\theta_1$', '$\\\\theta_2$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 8\n",
    "observation = jnp.array(twomoons.get_observation(idx))\n",
    "solver = ODESolver(velocity_model=vf_wrapped)  # create an ODESolver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_cond = dist.Independent(\n",
    "    dist.Normal(loc=jnp.zeros((2,)), scale=jnp.ones((2,))),\n",
    "    reinterpreted_batch_ndims=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 200\n",
    "x_1 = jnp.meshgrid(jnp.linspace(-1, 1, grid_size), jnp.linspace(-1, 1, grid_size))\n",
    "x_1 = jnp.stack([x_1[0].flatten(), x_1[1].flatten()], axis=1)\n",
    "\n",
    "# cond = jnp.broadcast_to(observation[...,None], (x_1.shape[0], dim_theta,1)) # n, dim_theta, 1\n",
    "# cond = jnp.broadcast_to(observation, (x_1.shape[0], dim_theta)) # n, dim_theta, 1\n",
    "cond = jnp.broadcast_to(observation, (1, dim_theta)) # n, dim_theta, 1\n",
    "\n",
    "obs_ids = jnp.array([0, 1])\n",
    "cond_ids = jnp.array([2, 3])\n",
    "model_extras = {\"cond\": cond, \"obs_ids\": obs_ids, \"cond_ids\": cond_ids, \"edge_mask\": posterior_faithfull}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the logprob\n",
    "# logp_sampler = solver.get_unnormalized_logprob(condition_mask=condition_mask, time_grid=[1.0,0.0],method='Dopri5', step_size=step_size, log_p0=p0_dist_model.log_prob, model_extras=model_extras)\n",
    "logp_sampler = solver.get_unnormalized_logprob(time_grid=[1.0,0.0],method='Dopri5', step_size=step_size, log_p0=p0_cond.log_prob, model_extras=model_extras)\n",
    "# create an y_init which has theta on the first position and x1,x2 on the second and third position\n",
    "\n",
    "# y_init = p0_cond.sample(jax.random.PRNGKey(0), (x_1.shape[0],))  # n, dim_theta\n",
    "y_init = x_1\n",
    "\n",
    "exact_log_p = logp_sampler(y_init)\n",
    "p = jnp.exp(exact_log_p)[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = p.reshape((grid_size, grid_size))\n",
    "plt.imshow(p_grid, origin='lower', aspect='auto', extent=(-1, 1, -1, 1), cmap='viridis')\n",
    "plt.xlim((-1,1))\n",
    "plt.ylim((-1,1))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample with guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvf_wrapped = GuidedSimWrapper(vf_cond, cfg_scale=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to do conditional inference. We need an observation for which we want to ocmpute the posterior\n",
    "idx=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples(gvf_wrapped, idx, nsamples=100_000, edge_mask=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = samples\n",
    "\n",
    "plt.hist2d(posterior_samples[:,0], posterior_samples[:,1], bins=100, range=[(-1, 1), (-1, 1)], density=True)\n",
    "# same ratio on axis \n",
    "# plt.scatter(reference_samples[:,0], reference_samples[:,1], s=0.1, color='red', alpha=0.1, marker='x')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plt.xlim((-1,1))\n",
    "# plt.ylim((-1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(np.array(posterior_samples), bins=100, smooth=True, range=[(-1, 1), (-1, 1)], labels=['$\\\\theta_1$', '$\\\\theta_2$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2ST test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbibm.metrics import c2st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert posterior samples to a torch array\n",
    "import torch\n",
    "idx = 2\n",
    "reference_samples = task.get_reference_posterior_samples(num_observation=idx)\n",
    "posterior_samples = get_samples(vf_wrapped, idx, nsamples=reference_samples.shape[0])[0]\n",
    "posterior_samples_torch = torch.tensor(np.array(posterior_samples), dtype=torch.float32)\n",
    "\n",
    "posterior_samples_cfg = get_samples(gvf_wrapped, idx, nsamples=reference_samples.shape[0], edge_mask=None)[0]\n",
    "posterior_samples_cfg_torch = torch.tensor(np.array(posterior_samples_cfg), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2st_accuracy = c2st(reference_samples, posterior_samples_torch)\n",
    "c2st_accuracy_cfg = c2st(reference_samples, posterior_samples_cfg_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2st_accuracy, c2st_accuracy_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
